# Multi-Agentic AI System for Multimodal Medical Diagnosis

## Overview

A comprehensive multi-agent AI system designed for multimodal medical diagnosis and consultation. This system intelligently routes medical queries and image uploads to specialized agents, providing evidence-based responses with human-in-the-loop validation for critical outputs.

**Key Features:**
- ğŸ¤– Multi-agent orchestration with LangGraph
- ğŸ¥ Specialized medical domain agents
- ğŸ–¼ï¸ Medical image analysis (Chest X-ray COVID-19 classification)
- ğŸ“š Retrieval-Augmented Generation (RAG) with Qdrant vector database
- ğŸŒ Web search integration for real-time medical information
- ğŸ›¡ï¸ Comprehensive input/output guardrails
- ğŸ¤ Voice input/output capabilities (speech-to-text, text-to-speech)
- âœ… Human-in-the-loop validation for high-risk outputs
- ğŸ”’ Session management and conversation memory

---

## ğŸ“ Project Structure

```
Multi-Agentic-AI-System-for-Multimodal-Medical-Diagnosis/
â”œâ”€â”€ agents/                          # Core agent implementations
â”‚   â”œâ”€â”€ agent_decision.py           # Agent routing logic & graph orchestration
â”‚   â”œâ”€â”€ guardrails/
â”‚   â”‚   â””â”€â”€ local_guardrails.py    # Input/output safety filters
â”‚   â”œâ”€â”€ image_analysis_agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ image_classifier.py    # Medical image classification
â”‚   â”‚   â””â”€â”€ chest_xray_agent/      # Chest X-ray specific models
â”‚   â”œâ”€â”€ rag_agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py            # MedicalRAG system coordinator
â”‚   â”‚   â”œâ”€â”€ doc_parser.py          # PDF parsing with Docling
â”‚   â”‚   â”œâ”€â”€ content_processor.py   # Document formatting & chunking
â”‚   â”‚   â”œâ”€â”€ vectorstore_qdrant.py  # Hybrid vector store (dense + sparse)
â”‚   â”‚   â”œâ”€â”€ reranker.py            # Cross-encoder reranking
â”‚   â”‚   â”œâ”€â”€ query_expander.py      # Query expansion with medical terminology
â”‚   â”‚   â””â”€â”€ response_generator.py  # RAG response generation with sources
â”‚   â””â”€â”€ web_search_processor_agent/
â”‚       â”œâ”€â”€ web_search_agent.py    # Web search orchestration
â”‚       â”œâ”€â”€ web_search_processor.py # Result processing
â”‚       â””â”€â”€ pubmed_search.py       # PubMed literature search (future)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ docs_db/                   # Local document store
â”‚   â”œâ”€â”€ qdrant_db/                 # Qdrant vector database
â”‚   â”œâ”€â”€ parsed_docs/               # Extracted document content
â”‚   â””â”€â”€ raw/                       # Raw ingestion files
â”œâ”€â”€ sample_images/
â”‚   â””â”€â”€ chest_x-ray_covid_and_normal/  # Test images
â”œâ”€â”€ uploads/
â”‚   â”œâ”€â”€ backend/                   # Temporary backend uploads
â”‚   â”œâ”€â”€ frontend/                  # Frontend-accessible uploads
â”‚   â””â”€â”€ speech/                    # Generated speech files
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                 # Web UI (Bootstrap + Vanilla JS)
â”œâ”€â”€ app.py                         # FastAPI backend server
â”œâ”€â”€ config.py                      # Centralized configuration
â”œâ”€â”€ rag_data_ingest.py            # Document ingestion CLI tool
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env                          # Environment variables (create this)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Architecture

### System Components

#### 1. **Agent Decision Router** ([`agents/agent_decision.py`](agents/agent_decision.py))
   - Routes user queries to the most appropriate agent
   - Implements LangGraph-based workflow orchestration
   - Manages conversation state and message history
   - Applies input/output guardrails
   - Orchestrates human validation when needed

   **Routing Logic:**
   - **IMAGE UPLOADED** â†’ Medical vision agent (Chest X-ray, etc.)
   - **Medical Knowledge Query** â†’ RAG Agent
   - **Time-Sensitive/Recent Info** â†’ Web Search Agent
   - **General Chat** â†’ Conversation Agent

#### 2. **Conversation Agent**
   - General medical conversation and clarification
   - Non-diagnostic Q&A
   - Handles follow-ups and context awareness
   - Routes complex queries to specialized agents

#### 3. **RAG Agent** ([`agents/rag_agent/`](agents/rag_agent/))
   - **Pipeline:**
     1. **Doc Parser** ([`doc_parser.py`](agents/rag_agent/doc_parser.py)): Extracts text, tables, images from PDFs using Docling
     2. **Content Processor** ([`content_processor.py`](agents/rag_agent/content_processor.py)): Summarizes images, formats documents, semantic chunking
     3. **Vector Store** ([`vectorstore_qdrant.py`](agents/rag_agent/vectorstore_qdrant.py)): Hybrid retrieval (dense embeddings + sparse BM25)
     4. **Query Expander** ([`query_expander.py`](agents/rag_agent/query_expander.py)): Enriches queries with medical terminology
     5. **Reranker** ([`reranker.py`](agents/rag_agent/reranker.py)): Cross-encoder reranking of results
     6. **Response Generator** ([`response_generator.py`](agents/rag_agent/response_generator.py)): Context-aware response generation with sources

   - **Key Features:**
     - LLM-based semantic chunking
     - Medical image summarization
     - Hybrid vector search (Qdrant)
     - Confidence scoring
     - Source attribution

#### 4. **Web Search Agent** ([`agents/web_search_processor_agent/`](agents/web_search_processor_agent/))
   - Real-time web search via Tavily
   - Medical literature search (PubMed support planned)
   - Result summarization
   - Fallback from RAG when confidence is low

#### 5. **Medical Vision Agent** ([`agents/image_analysis_agent/`](agents/image_analysis_agent/))
   - **Chest X-ray COVID-19 Classification**
   - Medical image classification pipeline
   - Outputs: POSITIVE (COVID-19), NEGATIVE (Normal), UNCLEAR
   - Requires human validation before display

#### 6. **Guardrails System** ([`agents/guardrails/local_guardrails.py`](agents/guardrails/local_guardrails.py))
   - **Input Guardrails:**
     - Blocks harmful, illegal, or unsafe requests
     - Prevents prompt injection attacks
     - Validates medical safety
   
   - **Output Guardrails:**
     - Reviews all agent responses for safety
     - Detects harmful medical advice
     - Revises unsafe content automatically
     - Adds disclaimers when needed

#### 7. **Human Validation** ([`agents/agent_decision.py`](agents/agent_decision.py))
   - Required for high-risk outputs (medical vision, certain RAG responses)
   - UI-based approval/rejection workflow
   - Feedback collection for output refinement

---

## ğŸ› ï¸ Configuration ([`config.py`](config.py))

All system configuration is centralized in [`config.py`](config.py):

```python
config.agent_decision          # Router LLM settings
config.conversation            # General conversation LLM
config.rag                     # RAG pipeline config
config.medical_cv              # Vision model paths
config.web_search              # Web search settings
config.speech                  # ElevenLabs API keys
config.validation              # Validation requirements
config.api                     # Server settings
config.ui                      # UI preferences
```

### Key Settings:

| Setting | Value | Purpose |
|---------|-------|---------|
| `RAG_TOP_K` | 5 | Number of documents to retrieve |
| `RERANKER_TOP_K` | 3 | Reranked results to use |
| `MIN_RETRIEVAL_CONFIDENCE` | 0.40 | Confidence threshold for RAG answers |
| `CHUNK_SIZE` | 512 | Document chunk size (tokens) |
| `CHUNK_OVERLAP` | 50 | Overlap between chunks |
| `COLLECTION_NAME` | `medical_assistance_rag` | Qdrant collection |
| `MAX_IMAGE_UPLOAD_SIZE` | 5 MB | Image upload limit |
| `MAX_CONVERSATION_HISTORY` | 20 | Messages to maintain |

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- Docker & Docker Compose (optional, for Qdrant)
- API Keys:
  - OpenAI (GPT-4o)
  - ElevenLabs (speech synthesis)
  - Tavily (web search)

### Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd Multi-Agentic-AI-System-for-Multimodal-Medical-Diagnosis
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables:**
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` with your API keys:
   ```env
   OPENAI_API_KEY=sk-...
   OPENAI_MODEL=gpt-4o
   OPENAI_EMBEDDING_MODEL=text-embedding-3-large
   ELEVEN_LABS_API_KEY=sk_...
   TAVILY_API_KEY=...
   HUGGINGFACE_TOKEN=hf_...
   QDRANT_URL=http://localhost:6333  # If using remote Qdrant
   QDRANT_API_KEY=...                 # If using remote Qdrant
   ```

5. **Start Qdrant (local):**
   ```bash
   docker run -p 6333:6333 qdrant/qdrant:latest
   ```

6. **Ingest medical documents (optional):**
   ```bash
   # Single file
   python rag_data_ingest.py --file data/raw/medical_paper.pdf
   
   # Directory of documents
   python rag_data_ingest.py --dir data/raw/
   ```

7. **Start the backend server:**
   ```bash
   python app.py
   ```
   
   Server runs at: `http://localhost:8000`

8. **Access the web UI:**
   ```
   http://localhost:8000
   ```

---

## ğŸ“š API Endpoints

### Health & UI

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/` | GET | Serve web UI (index.html) |
| `/health` | GET | Health check endpoint |

### Chat & Query

| Endpoint | Method | Purpose | Payload |
|----------|--------|---------|---------|
| `/chat` | POST | Text-only medical query | `{"query": "...", "conversation_history": []}` |
| `/upload` | POST | Image + optional text | Multipart form: `image`, `text` |

### Validation

| Endpoint | Method | Purpose | Payload |
|----------|--------|---------|---------|
| `/validate` | POST | Human validation response | Form: `validation_result`, `comments` |

### Speech

| Endpoint | Method | Purpose | Payload |
|----------|--------|---------|---------|
| `/transcribe` | POST | Speech-to-text (WebM/MP3) | Audio file |
| `/generate-speech` | POST | Text-to-speech (MP3) | `{"text": "...", "voice_id": "..."}` |

### Response Format

**Chat Response:**
```json
{
  "status": "success",
  "response": "Medical response text...",
  "agent": "RAG_AGENT",
  "confidence": 0.85,
  "sources": [
    {"title": "source_name", "path": "http://..."}
  ]
}
```

**Validation Response:**
```json
{
  "status": "validated",
  "message": "Output confirmed...",
  "response": "Final response..."
}
```

---

## ğŸ“– RAG Pipeline Details

### Document Ingestion Workflow

1. **Parsing** â†’ Docling extracts text, tables, images from PDFs
2. **Image Summarization** â†’ Vision LLM summarizes figures
3. **Content Formatting** â†’ Markdown formatting with embedded summaries
4. **Semantic Chunking** â†’ LLM-guided chunk merging/splitting
5. **Vectorization** â†’ OpenAI embeddings (text-embedding-3-large)
6. **Storage** â†’ Qdrant (dense + sparse vectors)

### Query Processing Workflow

1. **Input Guardrails** â†’ Safety validation
2. **Query Expansion** â†’ Medical terminology enrichment
3. **Retrieval** â†’ Hybrid search (dense + BM25)
4. **Reranking** â†’ Cross-encoder reranking
5. **Response Generation** â†’ Context-aware LLM response
6. **Source Attribution** â†’ Include document sources
7. **Confidence Scoring** â†’ Retrieval-based confidence
8. **Output Guardrails** â†’ Safety review & revision

### Vector Store Configuration

- **Database:** Qdrant
- **Dense Embeddings:** OpenAI `text-embedding-3-large` (3072-dim)
- **Sparse Embeddings:** FastEmbed BM25 (keyword matching)
- **Retrieval Mode:** Hybrid (combines both)
- **Distance Metric:** Cosine
- **Collection:** `medical_assistance_rag`

---

## ğŸ™ï¸ Voice Features

### Speech-to-Text
- **Provider:** ElevenLabs Scribe v1
- **Supported Format:** WebM (browser), converts to MP3
- **Features:** Language detection, audio event tagging, speaker diarization

### Text-to-Speech
- **Provider:** ElevenLabs
- **Voices:** Multiple pre-configured options
- **Settings:** Adjustable stability & similarity boost
- **Output:** MP3 stream

---

## ğŸ›¡ï¸ Safety & Validation

### Input Guardrails
Blocks:
- Harmful/illegal requests
- Self-harm content
- Prompt injection attacks
- Non-medical requests
- Copyright violations
- System prompt disclosure

### Output Guardrails
Reviews for:
- Medical misinformation
- Unsafe medical advice
- Overconfident claims
- Self-harm content
- Unauthorized medical practice
- Ethical violations

### Human Validation
**Required for:**
- âœ… Chest X-ray analysis (always)
- âœ… High-risk RAG outputs (insufficient confidence)
- âš ï¸ Sensitive medical responses

**Validation Workflow:**
1. System generates response
2. UI presents validation form (Yes/No)
3. Healthcare professional confirms/rejects
4. Feedback stored for monitoring

---

## ğŸ¨ Web UI ([`templates/index.html`](templates/index.html))

### Features

- **Responsive Design** (Bootstrap 5)
- **Real-time Chat** (Markdown support)
- **Image Upload** (medical images with preview)
- **Voice Controls:**
  - ğŸ¤ Record and transcribe speech
  - ğŸ”Š Play text responses as audio
  - ğŸ“Š Agent information sidebar
- **Conversation History** (session-based)
- **Visual Indicators:**
  - Thinking animations
  - Agent tags (colored badges)
  - Source attribution
  - Confidence levels

### Key Elements

| Element | Purpose |
|---------|---------|
| Chat Area | Message display with Markdown rendering |
| Input Box | Text/voice query input |
| File Upload | Medical image attachment |
| Sidebar | Agent info, capabilities, conversation controls |
| Audio Controls | TTS playback with pause/resume |
| Validation Form | Human confirmation UI for high-risk outputs |

---

## ğŸ“Š Conversation State Management

- **Backend State:** LangGraph with memory checkpointing
- **Session Tracking:** Cookie-based session IDs
- **Message History:** Limited to `MAX_CONVERSATION_HISTORY` messages
- **State Reset:** `/clear-chat` endpoint (frontend only)

---

## ğŸ” Key Classes & Functions

### RAG System ([`agents/rag_agent/__init__.py`](agents/rag_agent/__init__.py))

```python
class MedicalRAG:
    def ingest_file(file_path) â†’ Dict[success, chunks_processed, time]
    def ingest_directory(dir_path) â†’ Dict[success, documents_ingested, time]
    def process_query(query, chat_history) â†’ Dict[response, sources, confidence]
```

### Document Parsing ([`agents/rag_agent/doc_parser.py`](agents/rag_agent/doc_parser.py))

```python
class MedicalDocParser:
    def parse_document(
        document_path,
        output_dir,
        image_resolution_scale=2.0,
        do_ocr=True,
        do_tables=True,
        do_formulas=True,
        do_picture_desc=False
    ) â†’ Tuple[parsed_document, image_paths]
```

### Content Processing ([`agents/rag_agent/content_processor.py`](agents/rag_agent/content_processor.py))

```python
class ContentProcessor:
    def summarize_images(images) â†’ List[summaries]
    def format_document_with_images(doc, summaries) â†’ formatted_text
    def chunk_document(formatted_doc) â†’ List[semantic_chunks]
```

### Vector Store ([`agents/rag_agent/vectorstore_qdrant.py`](agents/rag_agent/vectorstore_qdrant.py))

```python
class VectorStore:
    def create_vectorstore(
        document_chunks,
        document_path
    ) â†’ Tuple[qdrant_vectorstore, docstore, doc_ids]
    def retrieve(query, top_k) â†’ List[retrieved_docs]
```

### Response Generation ([`agents/rag_agent/response_generator.py`](agents/rag_agent/response_generator.py))

```python
class ResponseGenerator:
    def generate_response(
        query,
        retrieved_docs,
        picture_paths,
        chat_history
    ) â†’ Dict[response, sources, confidence]
```

### Guardrails ([`agents/guardrails/local_guardrails.py`](agents/guardrails/local_guardrails.py))

```python
class LocalGuardrails:
    def check_input(user_input) â†’ "SAFE" | "UNSAFE: <reason>"
    def check_output(user_query, llm_output) â†’ revised_response | original_response
```

### Agent Decision ([`agents/agent_decision.py`](agents/agent_decision.py))

```python
def create_agent_graph() â†’ compiled_langgraph
def process_query(query, conversation_history) â†’ Dict[agent_name, output, messages]
def init_agent_state() â†’ AgentState
```

---

## ğŸ“¦ Key Dependencies

| Package | Purpose |
|---------|---------|
| `fastapi` | Web server framework |
| `langchain` | LLM orchestration |
| `langgraph` | Agent graph workflow |
| `qdrant-client` | Vector database client |
| `docling` | PDF parsing & extraction |
| `openai` | GPT-4o, embeddings |
| `elevenlabs` | Speech synthesis/recognition |
| `sentence-transformers` | Cross-encoder reranking |
| `tavily-python` | Web search |
| `torch` | Medical vision models |
| `pydub` | Audio processing |

See [`requirements.txt`](requirements.txt) for complete list.

---

## ğŸ§ª Testing & Validation

### Manual Testing

1. **Basic Chat:**
   ```
   User: "What are symptoms of COVID-19?"
   Expected: RAG_AGENT response with sources
   ```

2. **Image Upload:**
   ```
   User: [Upload chest X-ray] + "Is this COVID positive?"
   Expected: CHEST_XRAY_AGENT analysis + human validation UI
   ```

3. **Web Search:**
   ```
   User: "Latest COVID-19 treatment guidelines"
   Expected: WEB_SEARCH_PROCESSOR_AGENT response with recent data
   ```

4. **Voice:**
   ```
   User: [Speak medical question via microphone]
   Expected: Transcribed to text, processed, response played aloud
   ```

### Validation Checklist

- [ ] Guardrails block unsafe input
- [ ] Guardrails revise unsafe output
- [ ] RAG retrieval returns relevant docs
- [ ] Confidence scores correlate with quality
- [ ] Sources are accurately attributed
- [ ] Human validation UI appears for medical images
- [ ] Speech-to-text works with various accents
- [ ] TTS output is clear and natural
- [ ] Session state persists across requests
- [ ] Image upload handles various formats

---

## ğŸš¨ Limitations & Future Work

### Current Limitations
- âš ï¸ Medical image analysis limited to chest X-rays
- âš ï¸ Knowledge base limited to ingested documents
- âš ï¸ No integration with electronic health records (EHR)
- âš ï¸ Single-document summary only (multi-doc analysis planned)
- âš ï¸ Limited to English language
- âš ï¸ No persistent conversation storage (session-based only)

### Planned Enhancements
- ğŸ”œ PubMed literature search integration
- ğŸ”œ Multiple medical imaging modalities (CT, MRI, ultrasound)
- ğŸ”œ EHR system integration
- ğŸ”œ Multilingual support
- ğŸ”œ Persistent conversation logging
- ğŸ”œ Performance monitoring & observability
- ğŸ”œ Advanced reranking models
- ğŸ”œ Fine-tuned medical LLMs

---

## ğŸ“ Document Ingestion Examples

### Single File
```bash
python rag_data_ingest.py --file data/raw/covid_detection_paper.pdf
```

### Directory
```bash
python rag_data_ingest.py --dir data/raw/medical_papers/
```

### Output
```
Starting document ingestion process...

Ingestion result:
{
  "success": true,
  "documents_ingested": 1,
  "chunks_processed": 125,
  "processing_time": 45.32
}
```

---

## ğŸ”’ Security Considerations

### API Security
- âœ… Session cookies with secure flags
- âœ… Input validation (file type, size)
- âœ… Rate limiting (config: `rate_limit: 10`)
- âœ… CORS protection (frontend only)

### Data Privacy
- âš ï¸ Uploaded images stored temporarily in `/uploads/backend`
- âš ï¸ Speech files auto-cleaned every 5 minutes
- âš ï¸ No encryption at rest (recommended for production)
- âš ï¸ API keys stored in `.env` (not committed)

### Medical Safety
- âœ… Guardrails prevent diagnosis generation
- âœ… Human validation for critical outputs
- âœ… Confidence scoring to indicate uncertainty
- âœ… Clear disclaimers on limitations

---

## ğŸ“ Support & Troubleshooting

### Common Issues

**Issue:** Qdrant connection failed
```
Solution: Ensure Qdrant is running
docker run -p 6333:6333 qdrant/qdrant:latest
```

**Issue:** OpenAI API key invalid
```
Solution: Check .env file has correct key
export OPENAI_API_KEY=sk-...
```

**Issue:** Document ingestion slow
```
Solution: This is expected for large PDFs
- Docling processes each page
- Vision LLM summarizes images
- Typical: 5-10 min per 50-page document
```

**Issue:** Low retrieval confidence
```
Solution: 
- Add more documents to knowledge base
- Adjust RAG_CONFIG.min_retrieval_confidence
- Check query expansion is working (logs)
```

---

## ğŸ“– References & Resources

### Medical AI Papers
- COVID-19 Detection from Chest X-rays (training data included)
- Retrieval-Augmented Generation for Medical QA
- Medical NLP and Biomedical BERT models

### Libraries & Tools
- [LangChain Docs](https://python.langchain.com/)
- [LangGraph Docs](https://python.langchain.com/docs/langgraph/)
- [Qdrant Docs](https://qdrant.tech/documentation/)
- [Docling](https://ds4sd.github.io/docling/)
- [OpenAI API](https://platform.openai.com/docs/)
- [ElevenLabs API](https://elevenlabs.io/docs/)

---

## ğŸ“„ License

[Add your license here - MIT, Apache 2.0, etc.]

---

## ğŸ‘¥ Contributors

[List project contributors here]

---

## ğŸ“§ Contact & Questions

For questions, issues, or suggestions:
- Open a GitHub issue
- Contact: [email]
- Documentation: See `/docs` (if available)

---

## ğŸ¯ Quick Start Summary

```bash
# 1. Setup
git clone <repo>
cd Multi-Agentic-AI-System-for-Multimodal-Medical-Diagnosis
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env  # Add your API keys

# 2. Start Qdrant
docker run -p 6333:6333 qdrant/qdrant:latest

# 3. Ingest documents (optional)
python rag_data_ingest.py --dir data/raw/

# 4. Run server
python app.py

# 5. Access UI
# Open http://localhost:8000 in browser
```

---

**Last Updated:** 2024  
**Version:** 2.0  
**Status:** Active Development

